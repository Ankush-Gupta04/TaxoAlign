{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data\n",
    "file_path = '/kaggle/input/dataset/papers_cat.json'  # Replace with the actual file path\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert JSON data into a list of records\n",
    "records = []\n",
    "for key, value in data.items():\n",
    "    title = value.get(\"title\", \"\").strip()\n",
    "    abstract = value.get(\"abstract\", \"\").strip()\n",
    "    category = value.get(\"categories\", [None])[0]  # Use the first category\n",
    "    if title and abstract and category:  # Ensure no empty fields\n",
    "        records.append({\n",
    "            \"input_text\": f\"{title} {abstract}\",\n",
    "            \"category\": category\n",
    "        })\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())  # Preview the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define all categories with ACM subject names\n",
    "detailed_categories = [\n",
    "    {'category_code': 'cs.AI', 'category_name': 'Artificial Intelligence', 'acm_subject_names': [\n",
    "        'Artificial Intelligence', 'Applications and Expert Systems', 'Deduction and Theorem Proving',\n",
    "        'Knowledge Representation Formalisms and Methods', 'Problem Solving, Control Methods, and Search',\n",
    "        'Distributed Artificial Intelligence'\n",
    "    ]},\n",
    "    {'category_code': 'cs.AR', 'category_name': 'Hardware Architecture', 'acm_subject_names': [\n",
    "        'Computer Systems Organization', 'Processor Architectures', 'Computer System Implementation'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CC', 'category_name': 'Computational Complexity', 'acm_subject_names': [\n",
    "        'Computation by Abstract Devices', 'Tradeoffs between Complexity Measures', 'Formal Languages',\n",
    "        'Numerical Algorithms and Problems', 'Nonnumerical Algorithms and Problems'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CE', 'category_name': 'Computational Engineering, Finance, and Science', 'acm_subject_names': [\n",
    "        'Physical Sciences and Engineering', 'Life and Medical Sciences', 'Social and Behavioral Sciences'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CG', 'category_name': 'Computational Geometry', 'acm_subject_names': [\n",
    "        'Computational Geometry and Object Modeling', 'Nonnumerical Algorithms and Problems'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CL', 'category_name': 'Computation and Language', 'acm_subject_names': [\n",
    "        'Natural Language Processing'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CR', 'category_name': 'Cryptography and Security', 'acm_subject_names': [\n",
    "        'Security and Protection', 'Data Encryption'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CV', 'category_name': 'Computer Vision and Pattern Recognition', 'acm_subject_names': [\n",
    "        'Vision and Scene Understanding', 'Image Processing and Computer Vision', 'Pattern Recognition'\n",
    "    ]},\n",
    "    {'category_code': 'cs.CY', 'category_name': 'Computers and Society', 'acm_subject_names': [\n",
    "        'Computing Milieux', 'History of Computing', 'Computers and Education', 'Computers and Society',\n",
    "        'Legal Aspects of Computing', 'Computing Profession'\n",
    "    ]},\n",
    "    {'category_code': 'cs.DB', 'category_name': 'Databases', 'acm_subject_names': [\n",
    "        'Data Storage Representations', 'Files', 'Information Systems', 'Database Management',\n",
    "        'Administrative Data Processing'\n",
    "    ]},\n",
    "    {'category_code': 'cs.DC', 'category_name': 'Distributed, Parallel, and Cluster Computing', 'acm_subject_names': [\n",
    "        'Multiple Data Stream Architectures', 'Parallel Architectures', 'Distributed Systems',\n",
    "        'Concurrent Programming', 'Reliability', 'Organization and Design', 'Data Structures'\n",
    "    ]},\n",
    "    {'category_code': 'cs.DL', 'category_name': 'Digital Libraries', 'acm_subject_names': [\n",
    "        'Online Information Services', 'Library Automation', 'Digital Libraries', 'Document and Text Processing'\n",
    "    ]},\n",
    "    {'category_code': 'cs.DM', 'category_name': 'Discrete Mathematics', 'acm_subject_names': [\n",
    "        'Discrete Mathematics', 'Probability and Statistics'\n",
    "    ]},\n",
    "    {'category_code': 'cs.DS', 'category_name': 'Data Structures and Algorithms', 'acm_subject_names': [\n",
    "        'Data Structures', 'Data Storage Representations', 'Numerical Algorithms and Problems',\n",
    "        'Nonnumerical Algorithms and Problems'\n",
    "    ]},\n",
    "    {'category_code': 'cs.ET', 'category_name': 'Emerging Technologies', 'acm_subject_names': [\n",
    "        'CMOS-based technologies', 'Nanoscale Electronics', 'Photonics', 'Spintronics', 'Superconductors',\n",
    "        'Mechanical and Biochemical Technologies', 'Quantum Technologies'\n",
    "    ]},\n",
    "    {'category_code': 'cs.FL', 'category_name': 'Formal Languages and Automata Theory', 'acm_subject_names': [\n",
    "        'Models of Computation', 'Formal Languages'\n",
    "    ]},\n",
    "    {'category_code': 'cs.GL', 'category_name': 'General Literature', 'acm_subject_names': [\n",
    "        'Introductory and Survey', 'References, Dictionaries, Encyclopedias, Glossaries'\n",
    "    ]},\n",
    "    {'category_code': 'cs.GR', 'category_name': 'Graphics', 'acm_subject_names': [\n",
    "        'Graphics Systems', 'Picture or Image Generation', 'Graphics Utilities', 'Three-Dimensional Graphics and Realism'\n",
    "    ]},\n",
    "    {'category_code': 'cs.GT', 'category_name': 'Computer Science and Game Theory', 'acm_subject_names': [\n",
    "        'Mechanism Design', 'Learning in Games', 'Foundations of Agent Modeling in Games',\n",
    "        'Coordination in Non-Cooperative Environments'\n",
    "    ]},\n",
    "    {'category_code': 'cs.HC', 'category_name': 'Human-Computer Interaction', 'acm_subject_names': [\n",
    "        'User Interfaces', 'Group and Organization Interfaces', 'Hypertext or Hypermedia', 'Sound and Music Computing'\n",
    "    ]},\n",
    "    {'category_code': 'cs.IR', 'category_name': 'Information Retrieval', 'acm_subject_names': [\n",
    "        'Content Analysis and Indexing', 'Information Storage', 'Information Search and Retrieval', 'Systems and Software'\n",
    "    ]},\n",
    "    {'category_code': 'cs.IT', 'category_name': 'Information Theory', 'acm_subject_names': [\n",
    "        'Systems and Information Theory', 'Coding and Information Theory'\n",
    "    ]},\n",
    "    {'category_code': 'cs.LG', 'category_name': 'Machine Learning', 'acm_subject_names': [\n",
    "        'Supervised Learning', 'Unsupervised Learning', 'Reinforcement Learning', 'Bandit Problems', \n",
    "        'Robustness, Explanation, Fairness'\n",
    "    ]},\n",
    "    {'category_code': 'cs.LO', 'category_name': 'Logic in Computer Science', 'acm_subject_names': [\n",
    "        'Software or Program Verification', 'Specifying and Verifying and Reasoning About Programs',\n",
    "        'Mathematical Logic and Formal Languages', 'Grammars and Other Rewriting Systems', 'Formal Languages'\n",
    "    ]},\n",
    "\n",
    "    {'category_code': 'cs.MM', 'category_name': 'Multimedia', 'acm_subject_names': [\n",
    "        'Multimedia Information Systems'\n",
    "    ]},\n",
    "    {'category_code': 'cs.MS', 'category_name': 'Mathematical Software', 'acm_subject_names': [\n",
    "        'Mathematical Software'\n",
    "    ]},\n",
    "    {'category_code': 'cs.NA', 'category_name': 'Numerical Analysis', 'acm_subject_names': [\n",
    "        'Numerical Analysis'\n",
    "    ]},\n",
    "    {'category_code': 'cs.NE', 'category_name': 'Neural and Evolutionary Computing', 'acm_subject_names': [\n",
    "        'Other Architecture Styles', 'Learning', 'Pattern Recognition'\n",
    "    ]},\n",
    "    {'category_code': 'cs.NI', 'category_name': 'Networking and Internet Architecture', 'acm_subject_names': [\n",
    "        'Network Architecture and Design', 'Network Protocols', 'Network Operations', 'Distributed Systems',\n",
    "        'Local and Wide-Area Networks', 'Internetworking'\n",
    "    ]},\n",
    "    {'category_code': 'cs.OH', 'category_name': 'Other Computer Science', 'acm_subject_names': [\n",
    "        'Miscellaneous'\n",
    "    ]},\n",
    "    {\n",
    "    'category_code': 'cs.OS',\n",
    "    'category_name': 'Operating Systems',\n",
    "    'acm_subject_names': [\n",
    "        'Process Management', 'Storage Management', 'File Systems Management', \n",
    "        'Communications Management', 'Reliability', 'Organization and Design', \n",
    "        'Systems Programs and Utilities'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.PF',\n",
    "    'category_name': 'Performance',\n",
    "    'acm_subject_names': [\n",
    "        'Operating Systems Performance', 'Installation Management'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.PL',\n",
    "    'category_name': 'Programming Languages',\n",
    "    'acm_subject_names': [\n",
    "        'Programming Techniques', 'Programming Languages'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.RO',\n",
    "    'category_name': 'Robotics',\n",
    "    'acm_subject_names': [\n",
    "        'Robotics'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.SC',\n",
    "    'category_name': 'Symbolic Computation',\n",
    "    'acm_subject_names': [\n",
    "        'Symbolic and Algebraic Manipulation'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.SD',\n",
    "    'category_name': 'Sound',\n",
    "    'acm_subject_names': [\n",
    "        'Sound and Music Computing', 'User/Machine Systems', \n",
    "        'Multimedia Information Systems', 'User Interfaces', \n",
    "        'Natural Language Processing', 'Applications', 'Arts and Humanities', \n",
    "        'Social Issues'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.SE',\n",
    "    'category_name': 'Software Engineering',\n",
    "    'acm_subject_names': [\n",
    "        'Requirements or Specifications', 'Design Tools and Techniques', \n",
    "        'Coding Tools and Techniques', 'Testing and Debugging', \n",
    "        'Programming Environments', 'Distribution, Maintenance, and Enhancement', \n",
    "        'Metrics', 'Management', 'Design', 'Software Architectures', \n",
    "        'Interoperability', 'Reusable Software'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.SI',\n",
    "    'category_name': 'Social and Information Networks',\n",
    "    'acm_subject_names': [\n",
    "        'Analysis of Algorithms and Program Complexity', 'Discrete Mathematics', \n",
    "        'Probability and Statistics', 'Database Management', \n",
    "        'Artificial Intelligence', 'Information Storage and Retrieval', \n",
    "        'Information Systems Applications', 'Information Interfaces and Presentation', \n",
    "        'Administrative Data Processing', 'Physical Sciences and Engineering', \n",
    "        'Life and Medical Sciences', 'Social and Behavioral Sciences', \n",
    "        'Arts and Humanities', 'Computer Aided Engineering', \n",
    "        'Computer in Other Systems'\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    'category_code': 'cs.SY',\n",
    "    'category_name': 'Systems and Control',\n",
    "    'acm_subject_names': [\n",
    "        'Automotive and Aerospace Control Systems', 'Network Control', \n",
    "        'Biological Systems',  \n",
    "        'Robotics', 'Reinforcement Learning', 'Sensor Networks', \n",
    "        'Control of Cyber-Physical and Energy-Related Systems', \n",
    "        'Control of Computing Systems'\n",
    "    ]\n",
    "},\n",
    "{'category_code': 'cs.MA', 'category_name': 'Multiagent Systems', 'acm_subject_names': [\n",
    "    'Distributed Artificial Intelligence'\n",
    "]}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define categories and create mappings\n",
    "categories = [cat['category_code'] for cat in detailed_categories]\n",
    "label2id = {label: i for i, label in enumerate(categories)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Add label column to DataFrame\n",
    "df['label'] = df['category'].map(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert DataFrames to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def sample_dataset(dataset, num_samples_per_class=50):\n",
    "    labels = dataset[\"label\"]\n",
    "    indices_by_label = defaultdict(list)\n",
    "    \n",
    "    # Group indices by label\n",
    "    for i, lab in enumerate(labels):\n",
    "        indices_by_label[lab].append(i)\n",
    "    \n",
    "    # For each class, sample up to 'num_samples_per_class' examples\n",
    "    selected_indices = []\n",
    "    for lab, idx_list in indices_by_label.items():\n",
    "        if len(idx_list) > num_samples_per_class:\n",
    "            selected_indices.extend(random.sample(idx_list, num_samples_per_class))\n",
    "        else:\n",
    "            # If fewer than num_samples_per_class are available, take all\n",
    "            selected_indices.extend(idx_list)\n",
    "    \n",
    "    # Create a new dataset with the selected indices\n",
    "    return dataset.select(selected_indices)\n",
    "\n",
    "# Sample your train, val, and test datasets before tokenization\n",
    "train_dataset = sample_dataset(train_dataset, 100)\n",
    "val_dataset = sample_dataset(val_dataset, 100)\n",
    "test_dataset = sample_dataset(test_dataset, 100)\n",
    "\n",
    "# Now proceed with tokenization and formatting\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"input_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch_xla\n",
    "!pip install accelerate\n",
    "!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BartForSequenceClassification, BartTokenizer, Trainer, TrainingArguments\n",
    "import os\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# Environment variable to avoid fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"garbage_collection_threshold:0.6,max_split_size_mb:128\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "num_labels = len(categories)  # Ensure categories match the dataset\n",
    "model = BartForSequenceClassification.from_pretrained(\n",
    "    \"facebook/bart-large-mnli\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Training arguments with reduced batch size and mixed precision\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,  # Increase batch size if possible\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,  # Reduce learning rate\n",
    "    num_train_epochs=5,  # Train for more epochs\n",
    "    weight_decay=0.01,  # Add weight regularization\n",
    "    warmup_steps=500,  # Include warmup steps for stable training\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Free up GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Assume you have a test_dataset similar to train_dataset and val_dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_logits = predictions.predictions  # Raw logits\n",
    "pred_labels = predictions.label_ids    # True labels if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_text = [\"As the data size in Machine Learning fields grows exponentially, it is\\ninevitable to accelerate the computation by utilizing the ever-growing large\\nnumber of available cores provided by high-performance computing hardware.\\nHowever, existing parallel methods for clustering or regression often suffer\\nfrom problems of low accuracy, slow convergence, and complex\\nhyperparameter-tuning. Furthermore, the parallel efficiency is usually\\ndifficult to improve while striking a balance between preserving model\\nproperties and partitioning computing workloads on distributed systems. In this\\npaper, we propose a novel and simple data structure capturing the most\\nimportant information among data samples. It has several advantageous\\nproperties supporting a hierarchical clustering strategy that is irrelevant to\\nthe hardware parallelism, well-defined metrics for determining optimal\\nclustering, balanced partition for maintaining the compactness property, and\\nefficient parallelization for accelerating computation phases. Then we combine\\nthe clustering with regression techniques as a parallel library and utilize a\\nhybrid structure of data and model parallelism to make predictions. Experiments\\nillustrate that our library obtains remarkable performance on convergence,\\naccuracy, and scalability.\\n\"]\n",
    "test_inputs = [\" Modern Systems-on-Chip (SoC) designs are increasingly heterogeneous and\\ncontain specialized semi-programmable accelerators in addition to programmable\\nprocessors. In contrast to the pre-accelerator era, when the ISA played an\\nimportant role in verification by enabling a clean separation of concerns\\nbetween software and hardware, verification of these \\\"accelerator-rich\\\" SoCs\\npresents new challenges. From the perspective of hardware designers, there is a\\nlack of a common framework for the formal functional specification of\\naccelerator behavior. From the perspective of software developers, there exists\\nno unified framework for reasoning about software/hardware interactions of\\nprograms that interact with accelerators. This paper addresses these challenges\\nby providing a formal specification and high-level abstraction for accelerator\\nfunctional behavior. It formalizes the concept of an Instruction Level\\nAbstraction (ILA), developed informally in our previous work, and shows its\\napplication in modeling and verification of accelerators. This formal ILA\\nextends the familiar notion of instructions to accelerators and provides a\\nuniform, modular, and hierarchical abstraction for modeling software-visible\\nbehavior of both accelerators and programmable processors. We demonstrate the\\napplicability of the ILA through several case studies of accelerators (for\\nimage processing, machine learning, and cryptography), and a general-purpose\\nprocessor (RISC-V). We show how the ILA model facilitates equivalence checking\\nbetween two ILAs, and between an ILA and its hardware finite-state machine\\n(FSM) implementation. Further, this equivalence checking supports accelerator\\nupgrades using the notion of ILA compatibility, similar to processor upgrades\\nusing ISA compatibility.\\n\"]\n",
    "model.eval()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for input_text in test_inputs:\n",
    "    # Tokenize the input text\n",
    "    encoded_input = tokenizer(\n",
    "        input_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "\n",
    "    # Get the predicted class and its probability\n",
    "    predicted_class_id = torch.argmax(probs, dim=1).item()\n",
    "    predicted_label = id2label[predicted_class_id]\n",
    "    predicted_probability = probs[0, predicted_class_id].item()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Logits: {logits}\")\n",
    "    print(f\"Predicted Class ID: {predicted_class_id}\")\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "    print(f\"Predicted Probability: {predicted_probability:.4f}\")\n",
    "\n",
    "    # Print all class probabilities (optional)\n",
    "    print(\"\\nClass Probabilities:\")\n",
    "    for idx, prob in enumerate(probs[0]):\n",
    "        print(f\"  {id2label[idx]}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = \"/kaggle/working/fine_tuned_model\"\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!zip -r fine_tuned_model.zip /kaggle/working/fine_tuned_model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
