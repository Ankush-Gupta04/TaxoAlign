{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    hf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Pipeline\n",
    "generator = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=50,\n",
    "    repetition_penalty=1.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"\"\"\n",
    "<s>[INST]\n",
    "I have the following document:\n",
    "- The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken</s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_prompt = \"\"\"\n",
    "[INST]\n",
    "\n",
    "I have the following document:\n",
    "- [DOCUMENT]\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST]\n",
      "I have the following document:\n",
      "- The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
      "\n",
      "Please give me the keywords that are present in this document and separate them with commas.\n",
      "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
      "\"Here are the keywords present in the document\"\n",
      "[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken</s>\n",
      "[INST]\n",
      "\n",
      "I have the following document:\n",
      "- [DOCUMENT]\n",
      "\n",
      "Please give me the keywords that are present in this document and separate them with commas.\n",
      "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
      "\"Here are the keywords present in the document\"\n",
      "[/INST]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = example_prompt + keyword_prompt\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert.llm import TextGeneration\n",
    "from keybert import KeyLLM\n",
    "\n",
    "# Load it in KeyLLM\n",
    "llm = TextGeneration(generator, prompt=prompt)\n",
    "kw_model = KeyLLM(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"Deep learning, a subset of machine learning, has revolutionized the field of artificial intelligence by enabling computers to process and analyze large datasets. Convolutional neural networks (CNNs) have become the backbone of computer vision tasks, excelling in applications such as image recognition, object detection, and medical image analysis. Despite their success, these models often require extensive computational resources and large amounts of labeled data. Recent advancements in transfer learning and pre-trained models have mitigated these challenges by allowing models to generalize knowledge across tasks, reducing the need for task-specific training data.\"\n",
    "]\n",
    "\n",
    "# keywords = kw_model.extract_keywords(documents); keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyLLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Extract embeddings\n",
    "model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
    "embeddings = model.encode(documents, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it in KeyLLM\n",
    "kw_model = KeyLLM(llm)\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_model.extract_keywords(documents, embeddings=embeddings, threshold=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyLLM, KeyBERT\n",
    "\n",
    "# Load it in KeyLLM\n",
    "kw_model = KeyBERT(llm=llm, model='BAAI/bge-small-en-v1.5')\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_model.extract_keywords(documents, threshold=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deep learning',\n",
       "  'machine learning',\n",
       "  'artificial intelligence',\n",
       "  'convolutional neural networks',\n",
       "  'computer vision',\n",
       "  'image recognition',\n",
       "  'object detection',\n",
       "  'medical image analysis',\n",
       "  'computational resources',\n",
       "  'labeled data',\n",
       "  'transfer learning',\n",
       "  'pre-trained models',\n",
       "  'task-specific training data.']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
